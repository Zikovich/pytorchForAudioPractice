{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ScgEw-JA3cwK","executionInfo":{"status":"ok","timestamp":1670108565158,"user_tz":-60,"elapsed":21973,"user":{"displayName":"إسلام زيكوفتش","userId":"12934282606268707517"}},"outputId":"b09bd76a-507e-4dfd-b445-e4ffaba3bd4d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/mygithub/pytorchForAudioPractice"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"auvJlBnuwn-7","executionInfo":{"status":"ok","timestamp":1670069818978,"user_tz":-60,"elapsed":9,"user":{"displayName":"إسلام زيكوفتش","userId":"12934282606268707517"}},"outputId":"e237b241-1420-4ac9-ee5a-c1c4d6a66631"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1j0tKfNJ74iEAtyLmY4PY6L2fktF9jL1I/mygithub/pytorchForAudioPractice\n"]}]},{"cell_type":"code","source":["!pip install torch torchaudio torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yi2Z0c4bXtfd","executionInfo":{"status":"ok","timestamp":1670069822066,"user_tz":-60,"elapsed":3095,"user":{"displayName":"إسلام زيكوفتش","userId":"12934282606268707517"}},"outputId":"5304aa4c-4ec3-4270-daa0-ce46cab61de4"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.12.1+cu113)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.12.1+cu113)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.13.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.1.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n"]}]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import torch.autograd.profiler as profiler"],"metadata":{"id":"s8_9KJ0AYQ7F","executionInfo":{"status":"ok","timestamp":1670069822066,"user_tz":-60,"elapsed":10,"user":{"displayName":"إسلام زيكوفتش","userId":"12934282606268707517"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def download_mnist_datasets():\n","  train_data = datasets.MNIST(train=True, download=True, transform=ToTensor(), root=\"data\")\n","  validate_data = datasets.MNIST(train=False, download=True, transform=ToTensor(), root=\"data\")\n","  return train_data, validate_data\n"],"metadata":{"id":"nI8j0ZW9X3W4","executionInfo":{"status":"ok","timestamp":1670069822067,"user_tz":-60,"elapsed":10,"user":{"displayName":"إسلام زيكوفتش","userId":"12934282606268707517"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["from torch.nn.modules.linear import Linear\n","class FeedForwardNN(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.flatten = nn.Flatten()\n","    self.denseLayers = nn.Sequential(\n","        nn.Linear(28*28,256), # image size 28x28\n","        nn.ReLU(),\n","        nn.Linear(256,10) # 10 classes 0 to 9 \n","    )\n","    self.activation = nn.Softmax(dim=1)\n","\n","  def forward(self, inputData):\n","\n","    flattenedData = self.flatten(inputData)\n","    logits = self.denseLayers(flattenedData)\n","    predictions = self.activation(logits)\n","\n","    return predictions"],"metadata":{"id":"-z_FyG7fjjUG","executionInfo":{"status":"ok","timestamp":1670069822067,"user_tz":-60,"elapsed":10,"user":{"displayName":"إسلام زيكوفتش","userId":"12934282606268707517"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def trainOneEpoch(model, dataLoader, lossFn, optimiser, device):\n","\n","\n","  for input, target in dataLoader:\n","\n","    input, target = input.to(device), target.to(device)\n","\n","    #calculate loss\n","    predication = model(input)\n","\n","    loss = lossFn(predication, target)\n","\n","    # backpropagation and weight update\n","\n","    optimiser.zero_grad()\n","    loss.backward()\n","    optimiser.step()\n","\n","  print(f\"loss: {loss.item()}\")"],"metadata":{"id":"1l0qUQX1jp4I","executionInfo":{"status":"ok","timestamp":1670069822433,"user_tz":-60,"elapsed":375,"user":{"displayName":"إسلام زيكوفتش","userId":"12934282606268707517"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def train(model, dataLoader, lossFn, optimiser, device, epochs):\n","  for i in range(epochs):\n","\n","    print(f\"Epoch {i+1}\")\n","    trainOneEpoch(model, dataLoader, lossFn, optimiser, device)\n","    print(\"---------------------------\")\n","  \n","  print(\"Finished training\")"],"metadata":{"id":"JUEe9vv7oeFz","executionInfo":{"status":"ok","timestamp":1670069822433,"user_tz":-60,"elapsed":12,"user":{"displayName":"إسلام زيكوفتش","userId":"12934282606268707517"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["# **Model Train**"],"metadata":{"id":"rXT3qou62IWm"}},{"cell_type":"code","source":["BATCH_SIZE = 128\n","LEARNING_RATE = 0.001\n","EPOCHS = 10\n","\n","# Download data\n","train_data, _ = download_mnist_datasets()\n","\n","# data load\n","dataLoader = DataLoader(train_data, batch_size=BATCH_SIZE)\n","\n","# Build Model\n","\n","if torch.cuda.is_available():\n","    device = \"cuda\"\n","else:\n","    device = \"cpu\"\n","\n","print(f\"Using {device}\")\n","\n","model = FeedForwardNN().to(device)\n","\n","# Train\n","\n","lossFn = nn.CrossEntropyLoss()\n","optimiser = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","\n","train(model, dataLoader, lossFn, optimiser, device, EPOCHS)\n","\n","# Save Model\n","\n","torch.save(model.state_dict(),\"modelNN.pth\")\n","print(\"Trained feed forward net saved at modelNN.pth\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mYYtuBibjqR5","executionInfo":{"status":"ok","timestamp":1670069895079,"user_tz":-60,"elapsed":72657,"user":{"displayName":"إسلام زيكوفتش","userId":"12934282606268707517"}},"outputId":"a259acec-75e3-4efd-90b1-d73981561ec6"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu\n","Epoch 1\n","loss: 1.5117287635803223\n","---------------------------\n","Epoch 2\n","loss: 1.49992835521698\n","---------------------------\n","Epoch 3\n","loss: 1.4886845350265503\n","---------------------------\n","Epoch 4\n","loss: 1.4811148643493652\n","---------------------------\n","Epoch 5\n","loss: 1.475595474243164\n","---------------------------\n","Epoch 6\n","loss: 1.473410964012146\n","---------------------------\n","Epoch 7\n","loss: 1.4738837480545044\n","---------------------------\n","Epoch 8\n","loss: 1.4731812477111816\n","---------------------------\n","Epoch 9\n","loss: 1.4724453687667847\n","---------------------------\n","Epoch 10\n","loss: 1.4728208780288696\n","---------------------------\n","Finished training\n","Trained feed forward net saved at modelNN.pth\n"]}]},{"cell_type":"markdown","source":["# Model Infere"],"metadata":{"id":"H_VwYXy32STD"}},{"cell_type":"code","source":["CLASS_MAPPING = [\n","    \"0\",\n","    \"1\",\n","    \"2\",\n","    \"3\",\n","    \"4\",\n","    \"5\",\n","    \"6\",\n","    \"7\",\n","    \"8\",\n","    \"9\"\n","]"],"metadata":{"id":"a5PkQOx75Dcu","executionInfo":{"status":"ok","timestamp":1670070126513,"user_tz":-60,"elapsed":225,"user":{"displayName":"إسلام زيكوفتش","userId":"12934282606268707517"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def predict(model, input, target, classMapping):\n","  # switch eval \n","  model.eval()\n","\n","  # run infere without gradient evaluation\n","  with torch.no_grad():\n","    predictions = model(input)\n","\n","    # Tensor (1, 10) --> [[0.1, 0.001, .... , 0.8]]\n","    predictedIndex = predictions[0].argmax(0)\n","\n","    predicted = classMapping[predictedIndex]\n","    expected = classMapping[target]\n","\n","  return  predicted, expected"],"metadata":{"id":"yZztm4h04p0g","executionInfo":{"status":"ok","timestamp":1670070165002,"user_tz":-60,"elapsed":190,"user":{"displayName":"إسلام زيكوفتش","userId":"12934282606268707517"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Load Validate Data\n","_, validatingData = download_mnist_datasets()\n","\n","# Load Model\n","\n","feedForwardNetObj = FeedForwardNN()\n","\n","dictStatLoaded = torch.load(\"modelNN.pth\")\n","\n","feedForwardNetObj.load_state_dict(dictStatLoaded)\n","\n","# get sample from the validating data\n","input, target = validatingData[0][0], validatingData[0][1]\n","\n","# Make inference\n","\n","predicted, expected = predict(feedForwardNetObj, input, target, CLASS_MAPPING)\n","\n","print(f\"Predicted: '{predicted}', expected: '{expected}'\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1njFmwQEPybI","executionInfo":{"status":"ok","timestamp":1670070165439,"user_tz":-60,"elapsed":247,"user":{"displayName":"إسلام زيكوفتش","userId":"12934282606268707517"}},"outputId":"ccddb651-cf76-441c-d110-ab55e02f4d29"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted: '7', expected: '7'\n"]}]},{"cell_type":"markdown","source":["# Customized Urban Dataset\n","\n","https://urbansounddataset.weebly.com/urbansound8k.html"],"metadata":{"id":"DuIStHKi4GRP"}},{"cell_type":"markdown","source":["# To download dataset\n","\n","```\n","cd ---> path you need\n","!pip install opendatasets --upgrade --quiet\n","\n","import opendatasets as od\n","\n","dataset_url = 'https://goo.gl/8hY5ER'\n","od.download(dataset_url)\n","```\n","\n","ref: https://jovian.ai/charmzshab/urban-sound-dataset\n","\n","and also: https://www.kaggle.com/datasets/chrisfilo/urbansound8k"],"metadata":{"id":"6vCf2gSyFBcF"}},{"cell_type":"code","source":["import os\n","from torch.utils.data import Dataset\n","import pandas as pd\n","import torchaudio\n","\n","class UrbanSoundDataset(Dataset):\n","\n","  def __init__(self, annotationsFile, audioDir):\n","    self.annotations = pd.read_csv(annotationsFile)\n","    self.audioDir = audioDir\n","\n","  def __len__(self):\n","    return len(self.annotations)\n","    \n","  def __getitem__(self,index):\n","    audioSamplePath = self._getAudioSamplePath(index)\n","    label = self._getAudioSampleLabel(index)\n","    signal, sr = torchaudio.load(audioSamplePath)\n","    return signal, label\n","\n","  def _getAudioSamplePath(self, index):\n","    fold = f\"fold{self.annotations.iloc[index,5]}\" # 5 where fold is located he cloumb # 5\n","    path = os.path.join(self.audioDir, fold, self.annotations.iloc[index, 0]) # where 0 is the raw of the .wav files names\n","    return path\n","\n","  def _getAudioSampleLabel(self, index):\n","    return self.annotations.iloc[index, 6] # where the raw #6 is the classId"],"metadata":{"id":"I5wFi2J05_Kq","executionInfo":{"status":"ok","timestamp":1670108575989,"user_tz":-60,"elapsed":290,"user":{"displayName":"إسلام زيكوفتش","userId":"12934282606268707517"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["ANNOTATION_FILE = \"/content/drive/MyDrive/mygithub/pytorchForAudioPractice/data/UrbanSound8K/metadata/UrbanSound8K.csv\"\n","AUDIO_DIR = \"/content/drive/MyDrive/mygithub/pytorchForAudioPractice/data/UrbanSound8K/audio\"\n","\n","usd = UrbanSoundDataset(ANNOTATION_FILE, AUDIO_DIR)\n","\n","print(f\"There are {len(usd)} samples in the dataset.\")\n","signal, label = usd[0]\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IeP0godK5FyB","executionInfo":{"status":"ok","timestamp":1670108590517,"user_tz":-60,"elapsed":7176,"user":{"displayName":"إسلام زيكوفتش","userId":"12934282606268707517"}},"outputId":"ba98d850-3dfe-4b5c-8ab2-0fd3c96ab19b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 8732 samples in the dataset.\n"]}]},{"cell_type":"code","source":["label"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FaUgQJc5Nj1n","executionInfo":{"status":"ok","timestamp":1670108682038,"user_tz":-60,"elapsed":3,"user":{"displayName":"إسلام زيكوفتش","userId":"12934282606268707517"}},"outputId":"5c8c75e3-57a6-4211-dfc9-3f6dba8dc4bc"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[],"metadata":{"id":"fnl-5rCuOwZn"},"execution_count":null,"outputs":[]}]}